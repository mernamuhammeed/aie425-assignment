# @title Download and Extract Dataset
# Install gdown to download from Google Drive
!pip install -q gdown

import gdown
import zipfile
import os

# Define the Google Drive file ID from the provided link
file_id = '1wZgTBAFa0Q9pev7REIzE0wnjCuSu_Nxu'

# Construct the direct download URL for gdown
url = f'https://drive.google.com/uc?id={file_id}'

# Specify the name for the downloaded zip file
output_zip_path = 'ml-20m.zip'

print("Downloading the MovieLens 20M dataset...")
# Download the file using gdown
gdown.download(url, output_zip_path, quiet=False)

print(f"Downloaded {output_zip_path}")

# Define the directory to extract the contents
extract_dir = './ml-20m/'

print(f"Extracting {output_zip_path} to {extract_dir}...")
# Create the extraction directory if it doesn't exist
os.makedirs(extract_dir, exist_ok=True)

# Extract the zip file
with zipfile.ZipFile(output_zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_dir)

print("Extraction completed.")
print("\nListing extracted files:")
for file_name in os.listdir(extract_dir):
    print(file_name)
# === 1) Import Required Libraries ===
import pandas as pd
import numpy as np
from collections import Counter
import matplotlib.pyplot as plt

# === 2) Load the Dataset ===
# Path pointing to the ratings file inside the extracted MovieLens folder
ratings_path = os.path.join(extract_dir, 'ml-20m', 'ratings.csv')

print("Reading the ratings data ...")
ratings_df = pd.read_csv(ratings_path)

# === 3) Quick Inspection of the Dataset ===
print("Dataset successfully loaded!")
print(f"--> Number of rows and columns: {ratings_df.shape}\n")
print("Sample preview of the first records:")
print(ratings_df.head())

# ============================================
# Task 1 & 2: Dataset Overview and Rating Check
# ============================================

# Count the number of users, products, and ratings
total_users = ratings_df['userId'].nunique()
total_products = ratings_df['movieId'].nunique()
total_ratings = ratings_df.shape[0]

print(f"Total users: {total_users}")
print(f"Total products: {total_products}")
print(f"Total ratings: {total_ratings}")

# Check if the dataset meets minimum requirements
if total_users >= 100000 and total_products >= 1000 and total_ratings >= 1000000:
    print("✔ The dataset meets the minimum requirements.")
else:
    print("⚠ The dataset does NOT meet the minimum requirements.")

# ============================================
# Rating preprocessing: ensure ratings are on 1-5 scale
# ============================================

# Get unique rating values
unique_ratings = sorted(ratings_df['rating'].unique())
print(f"Sample of unique ratings: {unique_ratings[:10]} ... (total unique ratings: {len(unique_ratings)})")

# Verify that all ratings are within the expected range 0.5 - 5.0
if all(0.5 <= r <= 5.0 for r in unique_ratings):
    print("✔ Ratings are within the 0.5 to 5.0 range, suitable for 1-5 scale analysis.")
else:
    print("⚠ Some ratings fall outside the expected 0.5 - 5.0 range.")

# ============================================
# Additional analysis: rating distribution
# ============================================

# Count how many times each rating value occurs
rating_counts = ratings_df['rating'].value_counts().sort_index()
print("\nRating distribution:")
for rating, count in rating_counts.items():
    print(f"Rating {rating}: {count} occurrences")

# Optional: visualize the rating distribution using a simple bar chart
import matplotlib.pyplot as plt

plt.figure(figsize=(8,5))
plt.bar(rating_counts.index, rating_counts.values, color='skyblue')
plt.xlabel("Rating")
plt.ylabel("Number of Ratings")
plt.title("Distribution of Ratings in the Dataset")
plt.xticks(rating_counts.index)
plt.show()

# ============================================
# Task 3 & 4: Compute Rating Counts per User and per Item
# ============================================

# Calculate the total ratings submitted by each user
user_counts = ratings_df.groupby('userId')['rating'].count()
user_counts = user_counts.rename("nq")  # Rename for clarity
print("Preview of ratings per user (nq):")
print(user_counts.head())
print(f"Total number of users recorded: {user_counts.shape[0]}")

# Calculate the total ratings received by each item
item_counts = ratings_df.groupby('movieId')['rating'].count()
item_counts = item_counts.rename("ni")  # Rename for clarity
print("\nPreview of ratings per item (ni):")
print(item_counts.head())
print(f"Total number of items recorded: {item_counts.shape[0]}")

# Save the computed counts to CSV files for later use
user_counts.to_csv("user_rating_counts.csv", index=True)
item_counts.to_csv("item_rating_counts.csv", index=True)
print("\n✔ User and item rating counts have been successfully saved to CSV files.")

# ============================================
# Task 5 & 6: Compute Average Ratings per User and per Item
# ============================================

# Calculate the average rating for each user
user_avg = ratings_df.groupby('userId')['rating'].mean()
user_avg = user_avg.rename("rq")  # Rename for clarity

print("Preview of average ratings per user (rq):")
print(user_avg.sample(5, random_state=42))  # Display 5 random users

# Additional statistics for users
print("\nUser rating statistics:")
print(f"Minimum average rating: {user_avg.min():.2f}")
print(f"Maximum average rating: {user_avg.max():.2f}")
print(f"Overall average rating across users: {user_avg.mean():.2f}")

# Calculate the average rating for each item
item_avg = ratings_df.groupby('movieId')['rating'].mean()
item_avg = item_avg.rename("ri")  # Rename for clarity

print("\nPreview of average ratings per item (ri):")
print(item_avg.sample(5, random_state=42))  # Display 5 random items

# Additional statistics for items
print("\nItem rating statistics:")
print(f"Minimum average rating: {item_avg.min():.2f}")
print(f"Maximum average rating: {item_avg.max():.2f}")
print(f"Overall average rating across items: {item_avg.mean():.2f}")

# Save results to CSV files
user_avg.to_csv("avg_user_ratings.csv", index=True)
item_avg.to_csv("avg_item_ratings.csv", index=True)
print("\n✔ Average ratings for users and items have been saved to CSV files.")

# ============================================
# Task 7: Plot Distribution of Number of Ratings per Item (Sorted Ascending) with Log Scale
# ============================================

# Sort items by the number of ratings in ascending order
sorted_item_counts = item_counts.sort_values()

# Display basic statistics before plotting
print("Item rating count statistics:")
print(f"Minimum ratings for an item: {sorted_item_counts.min()}")
print(f"Maximum ratings for an item: {sorted_item_counts.max()}")
print(f"Median number of ratings: {sorted_item_counts.median()}")

# Optional: show top and bottom 5 items
print("\nBottom 5 items by rating count:")
print(sorted_item_counts.head())
print("\nTop 5 items by rating count:")
print(sorted_item_counts.tail())

# Plot the distribution
plt.figure(figsize=(10, 6))
plt.plot(sorted_item_counts.values, marker='o', linestyle='-', markersize=3, color='teal')
plt.title("Distribution of Number of Ratings per Item (Ascending Order)")
plt.xlabel("Item Index (Sorted by Rating Count)")
plt.ylabel("Number of Ratings")
plt.grid(True, linestyle='--', alpha=0.7)

# Apply logarithmic scale to better visualize the long-tail effect
plt.yscale("log")

plt.show()
# ============================================
# Task 8: Group Items by Average Rating (Equal Intervals)
# ============================================

import pandas as pd
import numpy as np

num_groups = 10  # Define number of groups

# Get min and max of average item ratings (item_avg)
min_rating, max_rating = item_avg.min(), item_avg.max()
print(f"Average rating range: {min_rating} to {max_rating}")

# Define 10 equal intervals
boundaries = np.linspace(min_rating, max_rating, num_groups + 1)

# Assign each item to a group (G1 to G10)
group_assignments = {
    item_id: f"G{min(np.digitize(avg, boundaries, right=False), num_groups)}"
    for item_id, avg in item_avg.items()
}

# Compute statistics per group
group_stats = {}
for item_id, group in group_assignments.items():
    if group not in group_stats:
        group_stats[group] = {'num_items': 0, 'total_ratings': 0}
    group_stats[group]['num_items'] += 1
    group_stats[group]['total_ratings'] += item_counts[item_id]  # 'item_counts' = ratings per item

# Convert to DataFrame for display
group_stats_df = pd.DataFrame.from_dict(group_stats, orient='index').reset_index()
group_stats_df.columns = ['group', 'num_items', 'total_ratings']

print("Group statistics (10 groups based on average rating intervals):")
print(group_stats_df)

# Save group assignments to CSV
pd.Series(group_assignments).to_csv('item_group_assignments_by_avg_rating_intervals.csv', index=True)
print("\n✔ Group assignments saved to CSV.")
# ============================================
# Task 9: Compute Total Ratings per Group and Visualize
# ============================================

import matplotlib.pyplot as plt

# Calculate total ratings per group
group_total_ratings = {}
for item_id, group_name in group_assignments.items():
    group_total_ratings[group_name] = group_total_ratings.get(group_name, 0) + item_counts[item_id]

# Display total ratings in original G1-G10 order
print("Total number of ratings per group (G1-G10 order):")
for i in range(1, 11):
    group_name = f"G{i}"
    total = group_total_ratings.get(group_name, 0)
    print(f"{group_name}: {total} ratings")

# Sort groups ascendingly by total ratings
sorted_group_ratings = dict(sorted(group_total_ratings.items(), key=lambda x: x[1]))

print("\nTotal number of ratings per group (Sorted ascendingly):")
for group, total in sorted_group_ratings.items():
    print(f"{group}: {total} ratings")

# Optional: plot the distribution as a bar chart
plt.figure(figsize=(8,5))
plt.bar(sorted_group_ratings.keys(), sorted_group_ratings.values(), color='skyblue')
plt.xlabel("Group")
plt.ylabel("Total Ratings")
plt.title("Total Ratings per Group (Ascending Order)")
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.show()
# ============================================
# Task 10: Plot Distribution of Ratings per Group (Original vs Ascending Order) with Log Scale
# ============================================

import matplotlib.pyplot as plt

plt.figure(figsize=(12, 5))

# ----- Plot 1: Original Order (G1 to G10) -----
plt.subplot(1, 2, 1)
# Ensure groups are in G1-G10 order
original_groups = sorted(group_total_ratings.keys(), key=lambda x: int(x[1:]))
original_ratings = [group_total_ratings[g] for g in original_groups]

plt.bar(original_groups, original_ratings, color='skyblue')
plt.title("Total Ratings per Group (Original Order)")
plt.xlabel("Group")
plt.ylabel("Total Ratings")
plt.yscale("log")  # Logarithmic scale for better visualization
plt.xticks(rotation=45)
plt.grid(axis='y', linestyle='--', alpha=0.7)

# ----- Plot 2: Ascending Order by Total Ratings -----
plt.subplot(1, 2, 2)
# Use previously sorted dictionary
sorted_groups = list(sorted_group_ratings.keys())
sorted_ratings = list(sorted_group_ratings.values())

plt.bar(sorted_groups, sorted_ratings, color='coral')
plt.title("Total Ratings per Group (Ascending Order)")
plt.xlabel("Group")
plt.ylabel("Total Ratings")
plt.yscale("log")  # Logarithmic scale
plt.xticks(rotation=45)
plt.grid(axis='y', linestyle='--', alpha=0.7)

plt.tight_layout()
plt.show()
# ============================================
# Task 11: Identify Three Target Users Based on Rating Activity
# ============================================

# Compute percentile rank for each user based on number of ratings (nq)
user_pct = user_counts.rank(pct=True)

# Function to select a user in a given percentile range
def select_user_by_percentile(pct_series, lower, upper):
    candidates = pct_series[(pct_series > lower) & (pct_series <= upper)]
    if candidates.empty:
        return None, None, None
    # Pick the user with the fewest ratings in the range
    user_id = candidates.idxmin()
    rating_count = user_counts[user_id]
    percentile_rank = pct_series[user_id] * 100
    return user_id, rating_count, percentile_rank

# Define percentile ranges for target users
U1_range = (0.0, 0.02)   # bottom 2%
U2_range = (0.02, 0.05)  # 2%-5%
U3_range = (0.05, 0.10)  # 5%-10%

# Select users
U1_id, U1_count, U1_pct = select_user_by_percentile(user_pct, *U1_range)
U2_id, U2_count, U2_pct = select_user_by_percentile(user_pct, *U2_range)
U3_id, U3_count, U3_pct = select_user_by_percentile(pct_series=user_pct, lower=U3_range[0], upper=U3_range[1])

# Display the selected target users
target_users = [
    ("U1", U1_id, U1_count, U1_pct),
    ("U2", U2_id, U2_count, U2_pct),
    ("U3", U3_id, U3_count, U3_pct)
]

print("Selected Target Users Based on Rating Percentiles:\n")
for name, uid, count, pct in target_users:
    if uid is not None:
        print(f"{name}: User ID {uid}, Ratings: {count}, Percentile: {pct:.2f}%")
    else:
        print(f"{name}: No user found in the specified percentile range.")
# ============================================
# Task 12: Identify Two Target Items with Lowest Ratings
# ============================================

# Sort items by rating count in ascending order (if not already sorted)
item_counts_sorted = item_counts.sort_values()

# Pick the two items with the fewest ratings
target_items = item_counts_sorted.head(2)

# Extract IDs and counts
I1_id, I1_count = target_items.index[0], target_items.iloc[0]
I2_id, I2_count = target_items.index[1], target_items.iloc[1]

# Display selected items
print("Selected Target Items Based on Rating Count:\n")
print(f"I1: Item ID {I1_id}, Number of Ratings: {I1_count}")
print(f"I2: Item ID {I2_id}, Number of Ratings: {I2_count}")
# ============================================
# Task 13: Count Co-rating Users and Co-rated Items (Optimized Version)
# ============================================

# Pre-compute mappings for efficiency
user_items = ratings_df.groupby('userId')['movieId'].apply(set).to_dict()
item_users = ratings_df.groupby('movieId')['userId'].apply(set).to_dict()

# ----- Target Users -----
target_users = [uid for uid in [U1_id, U2_id, U3_id] if uid is not None]
print("Co-rating analysis for target users:")

for uid in target_users:
    target_set = user_items[uid]
    # Count co-rated items with other users
    co_counts = {other: len(target_set & user_items[other])
                 for other in user_items if other != uid}
    co_counts = {k:v for k,v in co_counts.items() if v>0}

    top5 = sorted(co_counts.items(), key=lambda x: x[1], reverse=True)[:5]
    print(f"\nUser {uid}: {len(co_counts)} users share at least 1 item")
    print("Top 5 co-raters:")
    for other, cnt in top5:
        print(f"  user {other}: {cnt} co-rated items")

# ----- Target Items -----
target_items = [I1_id, I2_id]
print("\nCo-rating analysis for target items:")

for iid in target_items:
    target_set = item_users[iid]
    co_counts = {other: len(target_set & item_users[other])
                 for other in item_users if other != iid}
    co_counts = {k:v for k,v in co_counts.items() if v>0}

    top5 = sorted(co_counts.items(), key=lambda x: x[1], reverse=True)[:5]
    print(f"\nItem {iid}: {len(co_counts)} items share at least 1 rater")
    print("Top 5 co-rated items:")
    for other, cnt in top5:
        print(f"  item {other}: {cnt} co-rating users")

# ============================================
# Task 14: Compute Threshold S for Target Users
# ============================================

# Function to compute number of users who co-rated >= threshold_ratio of items with target user
def compute_threshold_s(target_uid, user_items_dict, threshold_ratio=0.3):
    target_set = user_items_dict.get(target_uid, set())
    if not target_set:
        return 0
    min_shared = len(target_set) * threshold_ratio
    # Count users meeting the threshold
    return sum(1 for other_uid, other_set in user_items_dict.items()
               if other_uid != target_uid and len(target_set & other_set) >= min_shared)

# Calculate Threshold S for each target user
threshold_s = {uid: compute_threshold_s(uid, user_items, 0.3) for uid in target_users}

# Display results
print("Threshold S (number of users who co-rated >=30% items with each target user):")
for uid, count in threshold_s.items():
    print(f"User {uid}: {count} users")

# ============================================
# Tasks 15 & 16: Dataset Summary, Sparsity, Bias, Long-tail Analysis
# ============================================

import matplotlib.pyplot as plt

# ---- Global Matrix Statistics ----
num_users, num_items, num_ratings = ratings_df['userId'].nunique(), ratings_df['movieId'].nunique(), len(ratings_df)
density = num_ratings / (num_users * num_items)
ssparsity = 1 - density

print("=== Global Matrix Statistics ===")
print(f"Users: {num_users}, Items: {num_items}, Ratings: {num_ratings}")
print(f"Density: {density:.8f}, Sparsity: {sparsity:.8f}")

# ---- Rating Bias Analysis ----
user_means = ratings_df.groupby('userId')['rating'].mean()
print("\n=== Rating Bias (User Means) ===")
print(f"Mean: {user_means.mean():.3f}, Std: {user_means.std():.3f}, Min/Max: {user_means.min():.1f}/{user_means.max():.1f}")

# ---- Long-Tail Analysis ----
sorted_items_desc = item_counts.sort_values(ascending=False)
cumulative_ratings = sorted_items_desc.cumsum()
print("\n=== Long-Tail Statistics ===")
for pct in [0.2, 0.5, 0.8]:
    target = pct * cumulative_ratings.iloc[-1]
    idx = (cumulative_ratings >= target).idxmax()
    position = sorted_items_desc.index.get_loc(idx) + 1
    print(f"Items for {int(pct*100)}% ratings: {position} ({position/len(sorted_items_desc)*100:.2f}% of items)")

# ---- Plots ----
plt.figure(figsize=(10,5))
plt.hist(user_avg.values, bins=50, edgecolor='k', alpha=0.7)
plt.title("Distribution of Average Rating per User")
plt.xlabel("Average Rating")
plt.ylabel("Number of Users")
plt.grid(True, linestyle='--', alpha=0.6)
plt.show()

plt.figure(figsize=(10,5))
plt.plot(range(1, len(sorted_items_desc)+1), cumulative_ratings.values, marker='.', markersize=1)
plt.title("Cumulative Ratings over Items (Long-tail)")
plt.xlabel("Item Index (Sorted by Rating Count Desc)")
plt.ylabel("Cumulative Ratings")
plt.xscale('log'); plt.yscale('log')
plt.grid(True, linestyle='--', alpha=0.6)
plt.show()

# ---- Threshold S / Beta Summary ----
beta = max(threshold_s.values()) if 'threshold_s' in locals() and threshold_s else 0

# ---- Insights ----
print("\n=== Dataset Insights ===")
print(f"- Dataset size: {num_ratings} ratings, {num_users} users, {num_items} items")
print(f"- Sparsity: {sparsity:.4f} → neighborhood formation is challenging")
print(f"- Rating bias: users tend to rate positively (mean {user_means.mean():.3f})")
print(f"- Long-tail: few items account for most ratings → fairness & novelty concerns")
print(f"- Co-rating analysis (Task 13) and Threshold S (Task 14, β={beta}) highlight limited overlaps among users")
# --- Section 2: Libraries & Data Preparation ---
import pandas as pd
import numpy as np
from collections import defaultdict
import warnings
warnings.simplefilter("ignore")  # Suppress warnings

# --- Ensure Section 1 variables exist ---
essential_vars = ['ratings_df', 'user_counts', 'item_counts', 'user_avg', 'item_avg', 'group_assignments', 'target_users', 'target_items', 'beta']
missing = [v for v in essential_vars if v not in globals()]
if missing:
    print(f"Error: Missing Section 1 variables: {missing}")
    print("Please execute Section 1 cells first.")
else:
    print("All required Section 1 variables are present.")
    print(f"Target Users: {target_users}")
    print(f"Target Items: {target_items}")
    print(f"Threshold Beta (S): {beta}")

    # --- Build utility matrices for efficient CF computations ---
    # Using dictionaries for sparse storage
    user_to_items = defaultdict(dict)  # user -> {item: rating}
    item_to_users = defaultdict(dict)  # item -> {user: rating}

    for index, row in ratings_df.iterrows():
        u = row['userId']
        i = row['movieId']
        r = row['rating']
        user_to_items[u][i] = r
        item_to_users[i][u] = r

    print("Utility matrices constructed successfully.")
    sample_user = target_users[0]
    sample_item = target_items[0]
    print(f"Example: User {sample_user} rated {len(user_to_items[sample_user])} items.")
    print(f"Example: Item {sample_item} rated by {len(item_to_users[sample_item])} users.")
# --- Part 1: User-Based CF - Case Study 1 (Reworked Version) ---
print("--- User-Based CF: Raw Cosine (Min Overlap = 5, Refined) ---")

def compute_cosine(u1, u2, ratings_map):
    """Compute cosine similarity between two users based on common ratings."""
    items_u1 = set(ratings_map[u1].keys())
    items_u2 = set(ratings_map[u2].keys())
    shared = items_u1 & items_u2

    min_common = 5
    if len(shared) < min_common:
        return 0.0

    dot = sum(ratings_map[u1][i] * ratings_map[u2][i] for i in shared)
    mag1 = np.sqrt(sum(ratings_map[u1][i]**2 for i in shared))
    mag2 = np.sqrt(sum(ratings_map[u2][i]**2 for i in shared))

    if mag1 * mag2 == 0:
        return 0.0

    return dot / (mag1 * mag2)

# --- Step 1: Raw cosine similarity ---
raw_sim_dict = {}
for user in target_users:
    print(f"\nCalculating similarities for User {user}...")
    sims = []
    for peer in user_item_matrix:
        if peer == user:
            continue
        score = compute_cosine(user, peer, user_item_matrix)
        if score > 0:
            sims.append((peer, score))
    sims.sort(key=lambda x: x[1], reverse=True)
    raw_sim_dict[user] = sims
    print(f"  Found {len(sims)} peers with sufficient overlap.")

# --- Step 2: Top 20% neighbors ---
top20_raw = {}
for user in target_users:
    peers = raw_sim_dict[user]
    k = max(1, int(0.2 * len(peers)))
    top20_raw[user] = peers[:k]
    print(f"\nTop 20% for User {user} (k={k}):")
    for uid, s in top20_raw[user][:5]:
        print(f"  Peer {uid}: similarity = {s:.4f}")

# --- Step 3: Predict unknown ratings using top 20% ---
pred_raw = {}
for user in target_users:
    neighbors = top20_raw[user]
    if not neighbors:
        pred_raw[user] = {}
        print(f"  Skipping predictions for User {user} (no neighbors).")
        continue

    candidate_items = set()
    for uid, _ in neighbors:
        candidate_items.update(user_item_matrix[uid].keys())
    unrated = candidate_items - set(user_item_matrix[user].keys())

    pred_ratings = {}
    for item in unrated:
        numerator = 0
        denominator = 0
        for uid, sim in neighbors:
            if item in user_item_matrix[uid]:
                numerator += sim * user_item_matrix[uid][item]
                denominator += abs(sim)
        pred_ratings[item] = numerator / denominator if denominator != 0 else user_avg[user]
    pred_raw[user] = pred_ratings
    print(f"  Predicted {len(pred_ratings)} items for User {user}. Sample: {dict(list(pred_ratings.items())[:3])}")

# --- Step 4: Discount Factor (DF) & Discounted Similarity (DS) ---
DS_dict = {}
for user in target_users:
    DS_list = []
    for peer, sim in raw_sim_dict[user]:
        shared = set(user_item_matrix[user].keys()) & set(user_item_matrix[peer].keys())
        threshold = user_counts[user] * 0.3
        DF = 1.0 if len(shared) >= threshold else min(1.0, len(shared)/threshold if threshold > 0 else 0.0)
        DS_list.append((peer, sim * DF))
    DS_list.sort(key=lambda x: x[1], reverse=True)
    DS_dict[user] = DS_list
    print(f"  DS calculated for {len(DS_list)} peers of User {user}.")

# --- Step 5: Top 20% neighbors based on DS ---
top20_DS = {}
for user in target_users:
    peers_DS = DS_dict[user]
    k_DS = max(1, int(0.2 * len(peers_DS)))
    top20_DS[user] = peers_DS[:k_DS]
    print(f"\nTop 20% DS neighbors for User {user} (k={k_DS}):")
    for uid, ds in top20_DS[user][:5]:
        print(f"  Peer {uid}: DS = {ds:.4f}")

# --- Step 6: Predict ratings using DS ---
pred_DS = {}
for user in target_users:
    neighbors = top20_DS[user]
    if not neighbors:
        pred_DS[user] = {}
        print(f"  Skipping DS predictions for User {user}.")
        continue

    candidate_items = set()
    for uid, _ in neighbors:
        candidate_items.update(user_item_matrix[uid].keys())
    unrated = candidate_items - set(user_item_matrix[user].keys())

    ratings_DS = {}
    for item in unrated:
        numerator = sum(ds * user_item_matrix[uid][item] for uid, ds in neighbors if item in user_item_matrix[uid])
        denominator = sum(abs(ds) for uid, ds in neighbors if item in user_item_matrix[uid])
        ratings_DS[item] = numerator / denominator if denominator != 0 else user_avg[user]
    pred_DS[user] = ratings_DS
    print(f"  Predicted {len(ratings_DS)} items using DS for User {user}. Sample: {dict(list(ratings_DS.items())[:3])}")

# --- Summary of top neighbors ---
top_raw_summary = {u: [uid for uid, _ in top20_raw[u][:5]] for u in target_users}
top_DS_summary = {u: [uid for uid, _ in top20_DS[u][:5]] for u in target_users}
print("\nSummary: Top 20% Neighbors (Raw vs DS)")
print("Raw:", top_raw_summary)
print("DS:", top_DS_summary)
#  Part 1: User-Based CF - Case Study 2: Mean-Centered Cosine Similarity (Refined with Min Overlap & Integrated CS1-CS2 Comparison for Step 9)
print("--- Part 1: User-Based CF - Case Study 2: Mean-Centered Cosine Similarity (Refined, Min Overlap = 5) ---")

def cosine_similarity_mean_centered(user1_id, user2_id, user_item_matrix, user_avg):
    """Calculate mean-centered cosine similarity between two users, considering only co-rated items."""
    items1 = set(user_item_matrix[user1_id].keys())
    items2 = set(user_item_matrix[user2_id].keys())
    common_items = items1.intersection(items2)

    # --- IMPROVEMENT: Check minimum overlap before calculating similarity ---
    min_overlap = 5 # Define a minimum number of co-rated items
    if len(common_items) < min_overlap:
        return 0.0 # Return 0 if not enough overlap

    # Calculate mean ratings for both users
    mean1 = user_avg[user1_id]
    mean2 = user_avg[user2_id]

    # Calculate centered ratings and sums
    sum1_sq = sum((user_item_matrix[user1_id][i] - mean1)**2 for i in common_items)
    sum2_sq = sum((user_item_matrix[user2_id][i] - mean2)**2 for i in common_items)
    sum_prod = sum((user_item_matrix[user1_id][i] - mean1) * (user_item_matrix[user2_id][i] - mean2) for i in common_items)

    denominator = np.sqrt(sum1_sq) * np.sqrt(sum2_sq)
    if denominator == 0:
        return 0.0

    return sum_prod / denominator

# --- Step 1: Calculate mean-centered cosine similarity (with minimum overlap check = 5) ---
similarity_scores_mc = {}
for target_user in target_users:
    print(f"\nCalculating mean-centered cosine similarities for target user {target_user} (min overlap = 5)...")
    similarities = []
    for other_user in user_item_matrix.keys():
        if other_user == target_user:
            continue # Skip self-similarity
        sim_score = cosine_similarity_mean_centered(target_user, other_user, user_item_matrix, user_avg)
        # Only store similarities > 0 (i.e., those that met the min overlap)
        if sim_score > 0:
            similarities.append((other_user, sim_score))

    # Sort by similarity (descending)
    similarities.sort(key=lambda x: x[1], reverse=True)
    similarity_scores_mc[target_user] = similarities
    print(f"  Calculated similarities with {len(similarities)} other users (after min overlap filter).")

# --- Step 2: Identify top 20% most similar users (using MC Cosine, after filtering with min overlap = 5) ---
top_20_percent_users_mc = {}
for target_user in target_users:
    total_users = len(similarity_scores_mc[target_user])
    if total_users == 0:
        print(f"  Warning: No users met the minimum overlap (5) criteria for target user {target_user}. Cannot select top 20%.")
        top_20_percent_users_mc[target_user] = []
        continue

    top_k = max(1, int(0.20 * total_users)) # Calculate 20% of the *filtered* list, ensure at least 1
    top_users = similarity_scores_mc[target_user][:top_k]
    top_20_percent_users_mc[target_user] = top_users
    print(f"\nTop 20% (k={top_k}) similar users for {target_user} (Mean-Centered Cosine, min overlap=5):")
    if top_users:
        for user_id, sim in top_users[:5]: # Print top 5 for brevity
            print(f"  User {user_id}: Sim = {sim:.4f}")
    else:
        print("  No users found after filtering.")

# --- Step 3: Predict unknown ratings using top 20% (MC Cosine, after filtering with min overlap = 5) ---
predictions_mc_cosine = {}
for target_user in target_users:
    if not top_20_percent_users_mc[target_user]: # Skip if no valid neighbors found
        print(f"  Skipping prediction for {target_user} due to no valid neighbors.")
        predictions_mc_cosine[target_user] = {}
        continue

    # Get all items rated by the top similar users but not by the target user
    candidate_items = set()
    top_user_ids = [u_id for u_id, sim in top_20_percent_users_mc[target_user]]
    for user_id in top_user_ids:
        candidate_items.update(user_item_matrix[user_id].keys())
    target_rated_items = set(user_item_matrix[target_user].keys())
    unrated_items = candidate_items - target_rated_items

    # Predict ratings for unrated items using Mean-Centered Cosine similarities
    predictions = {}
    mean_target = user_avg[target_user]
    for item_id in unrated_items:
        sum_sim_devs = 0
        sum_sims = 0
        for user_id, sim in top_20_percent_users_mc[target_user]:
            if item_id in user_item_matrix[user_id]:
                rating = user_item_matrix[user_id][item_id]
                mean_other = user_avg[user_id]
                deviation = rating - mean_other
                sum_sim_devs += sim * deviation
                sum_sims += abs(sim) # Use absolute value of the similarity

        if sum_sims != 0:
            predicted_rating = mean_target + (sum_sim_devs / sum_sims)
            predictions[item_id] = predicted_rating
        else:
            predictions[item_id] = mean_target # Fallback to target user's average

    predictions_mc_cosine[target_user] = predictions
    print(f"\nPredicted ratings for {len(predictions)} unrated items for {target_user} (MC Cosine, min overlap=5). Sample: {dict(list(predictions.items())[:3])}")

# --- Step 4: Calculate Discount Factor (DF) and then the Discounted Similarity (DS) using threshold §k30% ---
# Note: DF calculation still uses original user_counts[target_user] and the 30% threshold, but only for users who passed the min overlap check
DS_mc_cosine = {}
for target_user in target_users:
    DS_scores = []
    for other_user, raw_sim in similarity_scores_mc[target_user]: # Iterate only over users who had MC_sim > 0 (passed min overlap)
        # DF calculation (users who co-rated >= 30% of target_user's items)
        target_items_set = set(user_item_matrix[target_user].keys())
        other_items_set = set(user_item_matrix[other_user].keys())
        shared_items_count = len(target_items_set.intersection(other_items_set))
        min_shared_items_needed = user_counts[target_user] * 0.30 # Threshold §k30%

        if shared_items_count >= min_shared_items_needed:
            DF = 1.0
        else:
            DF = shared_items_count / min_shared_items_needed if min_shared_items_needed > 0 else 0.0
            DF = min(DF, 1.0) # Cap DF at 1.0

        DS = raw_sim * DF # Apply DF to the Mean-Centered Cosine similarity (which already passed min overlap)
        DS_scores.append((other_user, DS))

    # Sort by DS (descending)
    DS_scores.sort(key=lambda x: x[1], reverse=True)
    DS_mc_cosine[target_user] = DS_scores
    print(f"  Calculated DS for {len(DS_scores)} users (after min overlap=5) for {target_user}.")

# --- Step 5: Using the DS values, determine a new list of the top 20% most similar users (after filtering with min overlap = 5) ---
top_20_percent_users_DS_mc = {}
for target_user in target_users:
    total_users_DS = len(DS_mc_cosine[target_user])
    if total_users_DS == 0:
        print(f"  Warning: No users had DS calculated for target user {target_user} (min overlap=5). Cannot select top 20% DS.")
        top_20_percent_users_DS_mc[target_user] = []
        continue

    top_k_DS = max(1, int(0.20 * total_users_DS)) # Calculate 20% of the *DS list*, ensure at least 1
    top_users_DS = DS_mc_cosine[target_user][:top_k_DS]
    top_20_percent_users_DS_mc[target_user] = top_users_DS
    print(f"\nTop 20% (k={top_k_DS}) similar users for {target_user} (DS MC Cosine, min overlap=5):")
    if top_users_DS:
        for user_id, ds in top_users_DS[:5]: # Print top 5 for brevity
            print(f"  User {user_id}: DS = {ds:.4f}")
    else:
        print("  No users found for DS top-k.")

# --- Step 6: Again, use this updated similarity (DS) to predict missing ratings for each target user (after filtering with min overlap = 5) ---
predictions_DS_mc_cosine = {}
for target_user in target_users:
    if not top_20_percent_users_DS_mc[target_user]: # Skip if no valid DS neighbors found
        print(f"  Skipping DS prediction for {target_user} due to no valid DS neighbors.")
        predictions_DS_mc_cosine[target_user] = {}
        continue

    # Get all items rated by the top DS users but not by the target user
    candidate_items_DS = set()
    top_user_ids_DS = [u_id for u_id, ds in top_20_percent_users_DS_mc[target_user]]
    for user_id in top_user_ids_DS:
        candidate_items_DS.update(user_item_matrix[user_id].keys())
    target_rated_items_DS = set(user_item_matrix[target_user].keys())
    unrated_items_DS = candidate_items_DS - target_rated_items_DS

    # Predict ratings for unrated items using DS values
    predictions_DS = {}
    mean_target = user_avg[target_user]
    for item_id in unrated_items_DS:
        sum_DS_devs = 0
        sum_DSs = 0
        for user_id, DS in top_20_percent_users_DS_mc[target_user]:
            if item_id in user_item_matrix[user_id]:
                rating = user_item_matrix[user_id][item_id]
                mean_other = user_avg[user_id]
                deviation = rating - mean_other
                sum_DS_devs += DS * deviation
                sum_DSs += abs(DS) # Use absolute value of DS

        if sum_DSs != 0:
            predicted_rating = mean_target + (sum_DS_devs / sum_DSs)
            predictions_DS[item_id] = predicted_rating
        else:
            predictions_DS[item_id] = mean_target # Fallback to target user's average

    predictions_DS_mc_cosine[target_user] = predictions_DS
    print(f"\nPredicted ratings for {len(predictions_DS)} unrated items for {target_user} (DS MC Cosine, min overlap=5). Sample: {dict(list(predictions_DS.items())[:3])}")

    # --- CONCISE REPORTING: Show top 20% DS values, MC Similarity, and Discount Factor (DF) for this target user ---
    print(f"\n  >>> Values for Top 20% Neighbors of Target User {target_user} (k={top_k_DS}): <<<")
    for user_id, ds in top_20_percent_users_DS_mc[target_user][:20]: # Show values for top 20 neighbors
        # Get the original MC similarity for comparison
        mc_sim_for_comparison = next((sim for uid, sim in similarity_scores_mc[target_user] if uid == user_id), 0)
        # Recalculate the DF based on shared items and target user's threshold
        target_items_set = set(user_item_matrix[target_user].keys())
        other_items_set = set(user_item_matrix[user_id].keys())
        shared_items_count = len(target_items_set.intersection(other_items_set))
        threshold_k30 = 0.30 * user_counts[target_user]
        if threshold_k30 > 0:
            DF_recalculated = min(1.0, shared_items_count / threshold_k30)
        else:
            DF_recalculated = 0.0 # Should not happen if user has items

        print(f"    Neighbor {user_id}: DS = {ds:.4f}, MC_Sim = {mc_sim_for_comparison:.4f}, DF = {DF_recalculated:.4f}")

    # --- EXAMPLE SECTION: Show some neighbors with DF < 1.0 from the DS calculation phase ---
    print(f"\n  >>> Example Neighbors with DF < 1.0 for Target User {target_user} (during DS calculation): <<<")
    example_printed = 0
    for other_user, raw_sim in similarity_scores_mc[target_user]: # Iterate through users used in DS calculation
        if example_printed >= 5: # Limit examples printed
            break
        target_items_set = set(user_item_matrix[target_user].keys())
        other_items_set = set(user_item_matrix[other_user].keys())
        shared_items_count = len(target_items_set.intersection(other_items_set))
        threshold_k30 = 0.30 * user_counts[target_user]
        if threshold_k30 > 0:
            DF_example = min(1.0, shared_items_count / threshold_k30)
        else:
            DF_example = 0.0 # Should not happen if user has items

        if DF_example < 1.0: # Found a user with DF < 1.0
            DS_example = raw_sim * DF_example
            # Check if this user was NOT in the final top-k DS list
            top_user_ids_set = {uid for uid, ds_val in top_20_percent_users_DS_mc[target_user]}
            if other_user not in top_user_ids_set:
                print(f"    Neighbor {other_user}: DS = {DS_example:.4f}, MC_Sim = {raw_sim:.4f}, DF = {DF_example:.4f} (Shared Items: {shared_items_count}, Threshold: {threshold_k30:.2f})")
                example_printed += 1
    if example_printed == 0:
        print(f"    (No examples found with DF < 1.0 for this target user during DS calculation, or all were in the top-k list.)")


# --- Steps 7 & 8: Compare lists and predictions (will be analyzed in the report) ---
print("\n--- Case Study 2 Results Stored (Refined, Min Overlap = 5) ---")
# Only print lists if they exist
mc_top_users_dict = {}
for k, v in top_20_percent_users_mc.items():
    if v:
        mc_top_users_dict[k] = [u[0] for u in v[:5]] # Show first 5
    else:
        mc_top_users_dict[k] = []

DS_mc_top_users_dict = {}
for k, v in top_20_percent_users_DS_mc.items():
    if v:
        DS_mc_top_users_dict[k] = [u[0] for u in v[:5]] # Show first 5
    else:
        DS_mc_top_users_dict[k] = []

print("MC Cosine Similarity Top 20% Users (min overlap=5):", mc_top_users_dict)
print("DS MC Cosine Top 20% Users (min overlap=5):", DS_mc_top_users_dict)

# --- Step 9: Compare Raw Cosine (CS1) and Mean-Centered Cosine (CS2) similarities ---
print("\n--- Case Study 2 Step 9: Comparing Raw Cosine (CS1) vs Mean-Centered Cosine (CS2) ---")
# This step requires the results from Case Study 1 (Raw Cosine similarities: similarity_scores_raw)
# Check if CS1 results are available in the current environment
if 'raw_sim_dict' in globals(): # Changed from similarity_scores_raw to raw_sim_dict
    print("Comparing Raw Cosine (CS1) and Mean-Centered Cosine (CS2) similarities for Step 9...")
    cs2_step9_found_flipped = False
    for target_user in target_users:
        print(f"\n  Analyzing target user {target_user}:")
        # Get raw similarities for this target user (from CS1 results stored in raw_sim_dict)
        raw_sims_dict = dict(raw_sim_dict[target_user])
        # Get MC similarities for this target user (from CS2 results stored in similarity_scores_mc)
        mc_sims_dict = dict(similarity_scores_mc[target_user])

        # Find users who are common in both similarity lists (passed min overlap for both)
        common_users = set(raw_sims_dict.keys()).intersection(set(mc_sims_dict.keys()))

        # Look for pairs where Raw Cosine is highly positive and MC Cosine is -1.0
        # Adjust thresholds if needed (e.g., raw > 0.9 and mc = -1.0)
        high_pos_raw_neg_one_mc = [(v, raw_sims_dict[v], mc_sims_dict[v])
                                   for v in common_users
                                   if raw_sims_dict[v] > 0.9 and mc_sims_dict[v] == -1.0]

        if high_pos_raw_neg_one_mc:
            cs2_step9_found_flipped = True
            print(f"    Users with Raw Cosine > 0.9 and MC Cosine = -1.0 for target {target_user}:")
            for user_id, raw_sim, mc_sim in high_pos_raw_neg_one_mc[:10]: # Show first 10 examples
                print(f"      User {user_id}: Raw_Cos = {raw_sim:.4f}, MC_Sim = {mc_sim:.4f}")
        else:
            print(f"    No users found with Raw_Sim > 0.9 and MC_Sim = -1.0 for target {target_user}.")

    if not cs2_step9_found_flipped:
        print("\n  No users found across all targets where Raw Cosine was highly positive (e.g., >0.9) and MC Cosine was exactly -1.0.")
        print("  This suggests that the mean-centering did not flip the sign for highly positive raw cosine pairs in this dataset/run,")
        print("  or the thresholds need adjustment (e.g., Raw>0.8, MC<-0.8), or the min_overlap=5 filter already removed such scenarios.")
        print("  The assignment asks for MC_Sim = -1.0, which is a very specific outcome requiring perfectly opposite rating patterns relative to means.")
        print("  It's possible to find cases where MC_Sim is negative but not exactly -1.0 when Raw_Sim is highly positive.")
        # Optional: Loosen the criteria slightly to find negative MC with positive Raw
        for target_user in target_users:
            raw_sims_dict = dict(raw_sim_dict[target_user]) # Changed from similarity_scores_raw
            mc_sims_dict = dict(similarity_scores_mc[target_user])
            common_users = set(raw_sims_dict.keys()).intersection(set(mc_sims_dict.keys()))
            # Look for pairs where Raw Cosine is highly positive and MC Cosine is *any* negative value
            high_pos_raw_neg_any_mc = [(v, raw_sims_dict[v], mc_sims_dict[v])
                                       for v in common_users
                                       if raw_sims_dict[v] > 0.8 and mc_sims_dict[v] < -0.5] # Example looser criteria
            if high_pos_raw_neg_any_mc:
                print(f"\n    (Loose search) Users with Raw Cosine > 0.8 and MC Cosine < -0.5 for target {target_user}:")
                for user_id, raw_sim, mc_sim in high_pos_raw_neg_any_mc[:5]: # Show first 5 examples
                    print(f"      User {user_id}: Raw_Cos = {raw_sim:.4f}, MC_Sim = {mc_sim:.4f}")

    # --- Step 9 Analysis for Report ---
    print("\n  Analysis for Report (Step 9):")
    print("    - Users where Raw Cosine is highly positive but MC Cosine is negative (or -1.0) rated common items in opposing patterns relative to their own average ratings.")
    print("    - Raw Cosine measures the *direction* of absolute ratings (e.g., both high/low).")
    print("    - MC Cosine measures the *direction* of deviations from the user's mean (e.g., both rated items higher/lower than their own average).")
    print("    - A high Raw Cosine and a negative MC Cosine indicates agreement on *absolute* rating levels (e.g., both gave high scores) but disagreement on *relative* preference compared to their personal baseline.")
    print("    - Users with high similarity in BOTH Raw Cosine AND Mean-Centered Cosine are likely to have more robust agreement that accounts for user bias, making them potentially more reliable neighbors for prediction than users where the signs differ significantly.")
else:
    print("\n  Warning: 'raw_sim_dict' (from Case Study 1) not found in current environment.") # Changed from similarity_scores_raw
    print("  Cannot perform the comparison requested in Step 9 (Raw Cosine vs MC Cosine).")
    print("  Please ensure the Case Study 1 cell has been run successfully in the same session before running Case Study 2.")

# --- Steps 10 & 11: Analysis points (will be addressed in the report) ---
print("\n--- Case Study 2 Analysis Points (Refined, Min Overlap = 5) ---")
print("10. Trust based on common items: Mean-centering explicitly accounts for user rating bias, making agreement on common items more meaningful than Raw Cosine.")
print("11. Report comments: Discuss the impact of min overlap=5, DS, and the advantages of mean-centering over raw cosine for handling user rating biases.")
# @title Part 1: User-Based CF - Case Study 3: Pearson Correlation Coefficient (PCC) (Refined with Min Overlap & CS1-CS3 Comparison for Step 9)
print("--- Part 1: User-Based CF - Case Study 3: Pearson Correlation Coefficient (PCC) (Refined, Min Overlap = 5) ---")

def pcc_similarity(user1_id, user2_id, user_item_matrix, user_avg):
    """Calculate Pearson Correlation Coefficient similarity between two users, considering only co-rated items."""
    items1 = set(user_item_matrix[user1_id].keys())
    items2 = set(user_item_matrix[user2_id].keys())
    common_items = items1.intersection(items2)

    # --- IMPROVEMENT: Check minimum overlap before calculating PCC ---
    min_overlap = 5 # Define a minimum number of co-rated items (PCC technically needs 2, but 5 is more robust)
    if len(common_items) < min_overlap:
        return 0.0 # Return 0 if not enough overlap

    mean1 = user_avg[user1_id]
    mean2 = user_avg[user2_id]

    numerator = sum((user_item_matrix[user1_id][i] - mean1) * (user_item_matrix[user2_id][i] - mean2) for i in common_items)
    sum_sq_diff1 = sum((user_item_matrix[user1_id][i] - mean1)**2 for i in common_items)
    sum_sq_diff2 = sum((user_item_matrix[user2_id][i] - mean2)**2 for i in common_items)

    denominator = np.sqrt(sum_sq_diff1) * np.sqrt(sum_sq_diff2)
    if denominator == 0:
        return 0.0 # Avoid division by zero

    pcc = numerator / denominator
    return pcc

# --- Step 1: Calculate PCC similarity (with minimum overlap check = 5) ---
similarity_scores_pcc = {}
for target_user in target_users:
    print(f"\nCalculating PCC similarities for target user {target_user} (min overlap = 5)...")
    similarities = []
    for other_user in user_item_matrix.keys():
        if other_user == target_user:
            continue
        sim_score = pcc_similarity(target_user, other_user, user_item_matrix, user_avg)
        # Only store similarities > 0 (i.e., those that met the min overlap)
        if sim_score > 0:
            similarities.append((other_user, sim_score))

    # Sort by similarity (descending)
    similarities.sort(key=lambda x: x[1], reverse=True)
    similarity_scores_pcc[target_user] = similarities
    print(f"  Calculated similarities with {len(similarities)} other users (after min overlap filter).")

# --- Step 2: Identify top 20% most similar users (using PCC, after filtering with min overlap = 5) ---
top_20_percent_users_pcc = {}
for target_user in target_users:
    total_users = len(similarity_scores_pcc[target_user])
    if total_users == 0:
        print(f"  Warning: No users met the minimum overlap (5) criteria for target user {target_user}. Cannot select top 20%.")
        top_20_percent_users_pcc[target_user] = []
        continue

    top_k = max(1, int(0.20 * total_users)) # Calculate 20% of the *filtered* list, ensure at least 1
    top_users = similarity_scores_pcc[target_user][:top_k]
    top_20_percent_users_pcc[target_user] = top_users
    print(f"\nTop 20% (k={top_k}) similar users for {target_user} (PCC, min overlap=5):")
    if top_users:
        for user_id, sim in top_users[:5]: # Print top 5 for brevity
            print(f"  User {user_id}: Sim = {sim:.4f}")
    else:
        print("  No users found after filtering.")

# --- Step 3: Predict unknown ratings using top 20% (PCC, after filtering with min overlap = 5) ---
predictions_pcc = {}
for target_user in target_users:
    if not top_20_percent_users_pcc[target_user]: # Skip if no valid neighbors found
        print(f"  Skipping prediction for {target_user} due to no valid neighbors.")
        predictions_pcc[target_user] = {}
        continue

    # Get all items rated by the top similar users but not by the target user
    candidate_items = set()
    top_user_ids = [u_id for u_id, sim in top_20_percent_users_pcc[target_user]]
    for user_id in top_user_ids:
        candidate_items.update(user_item_matrix[user_id].keys())
    target_rated_items = set(user_item_matrix[target_user].keys())
    unrated_items = candidate_items - target_rated_items

    # Predict ratings for unrated items using PCC
    predictions = {}
    mean_target = user_avg[target_user]
    for item_id in unrated_items:
        sum_sim_devs = 0
        sum_sims = 0
        for user_id, sim in top_20_percent_users_pcc[target_user]:
            if item_id in user_item_matrix[user_id]:
                rating = user_item_matrix[user_id][item_id]
                mean_other = user_avg[user_id]
                deviation = rating - mean_other
                sum_sim_devs += sim * deviation
                sum_sims += abs(sim)

        if sum_sims != 0:
            predicted_rating = mean_target + (sum_sim_devs / sum_sims)
            predictions[item_id] = predicted_rating
        else:
            predictions[item_id] = mean_target # Fallback to target user's average

    predictions_pcc[target_user] = predictions
    print(f"\nPredicted ratings for {len(predictions)} unrated items for {target_user} (PCC, min overlap=5). Sample: {dict(list(predictions.items())[:3])}")

# --- Step 4: Calculate Discount Factor (DF) and Discounted Similarity (DS) ---
# Note: The question "Is it correct to compute DF and DS?" is answered YES in the report context.
# The implementation proceeds as the similarity reflects agreement, and DS adds confidence based on overlap.
print("\nStep 4: Computing DF and DS is applicable to PCC to incorporate co-rating significance.")

DS_pcc = {}
for target_user in target_users:
    DS_scores = []
    for other_user, raw_sim in similarity_scores_pcc[target_user]: # Iterate only over users who passed min overlap
        # DF calculation (users who co-rated >= 30% of target_user's items)
        target_items_set = set(user_item_matrix[target_user].keys())
        other_items_set = set(user_item_matrix[other_user].keys())
        shared_items_count = len(target_items_set.intersection(other_items_set))
        min_shared_items_needed = user_counts[target_user] * 0.30 # Threshold §k30%

        if min_shared_items_needed > 0 and shared_items_count >= min_shared_items_needed:
            DF = 1.0
        elif min_shared_items_needed > 0:
            DF = shared_items_count / min_shared_items_needed
            DF = min(DF, 1.0) # Cap DF at 1.0
        else: # Handle case where min_shared_items_needed is 0 (e.g., user has 0 ratings)
            DF = 0.0

        DS = raw_sim * DF # Apply DF to the PCC similarity (which already passed min overlap)
        DS_scores.append((other_user, DS))

    # Sort by DS (descending)
    DS_scores.sort(key=lambda x: x[1], reverse=True)
    DS_pcc[target_user] = DS_scores
    print(f"  Calculated DS for {len(DS_scores)} users (after min overlap=5) for {target_user}.")

# --- Step 5: Identify top 20% most similar users using DS (PCC, after filtering with min overlap = 5) ---
top_20_percent_users_DS_pcc = {}
for target_user in target_users:
    total_users = len(DS_pcc[target_user])
    if total_users == 0:
        print(f"  Warning: No users had DS calculated for target user {target_user} (min overlap=5). Cannot select top 20% DS.")
        top_20_percent_users_DS_pcc[target_user] = []
        continue

    top_k = max(1, int(0.20 * total_users)) # Calculate 20% of the *DS list*, ensure at least 1
    top_users_DS = DS_pcc[target_user][:top_k]
    top_20_percent_users_DS_pcc[target_user] = top_users_DS
    print(f"\nTop 20% (k={top_k}) similar users for {target_user} (DS PCC, min overlap=5):")
    if top_users_DS:
        for user_id, ds in top_users_DS[:5]: # Print top 5 for brevity
            print(f"  User {user_id}: DS = {ds:.4f}")
    else:
        print("  No users found for DS top-k.")

# --- Step 6: Predict ratings again using DS (PCC) (after filtering with min overlap = 5) ---
predictions_DS_pcc = {}
for target_user in target_users:
    if not top_20_percent_users_DS_pcc[target_user]: # Skip if no valid DS neighbors found
        print(f"  Skipping DS prediction for {target_user} due to no valid DS neighbors.")
        predictions_DS_pcc[target_user] = {}
        continue

    # Get all items rated by the top DS users but not by the target user
    candidate_items = set()
    top_user_ids_DS = [u_id for u_id, ds in top_20_percent_users_DS_pcc[target_user]]
    for user_id in top_user_ids_DS:
        candidate_items.update(user_item_matrix[user_id].keys())
    target_rated_items = set(user_item_matrix[target_user].keys())
    unrated_items = candidate_items - target_rated_items

    # Predict ratings for unrated items using DS values
    predictions_DS = {}
    mean_target = user_avg[target_user]
    for item_id in unrated_items:
        sum_DS_devs = 0
        sum_DSs = 0
        for user_id, DS in top_20_percent_users_DS_pcc[target_user]:
            if item_id in user_item_matrix[user_id]:
                rating = user_item_matrix[user_id][item_id]
                mean_other = user_avg[user_id]
                deviation = rating - mean_other
                sum_DS_devs += DS * deviation
                sum_DSs += abs(DS)

        if sum_DSs != 0:
            predicted_rating = mean_target + (sum_DS_devs / sum_DSs)
            predictions_DS[item_id] = predicted_rating
        else:
            predictions_DS[item_id] = mean_target # Fallback to target user's average

    predictions_DS_pcc[target_user] = predictions_DS
    print(f"\nPredicted ratings for {len(predictions_DS)} unrated items for {target_user} (DS PCC, min overlap=5). Sample: {dict(list(predictions_DS.items())[:3])}")

    # --- CONCISE REPORTING: Show top 20% DS values, PCC Similarity, and Discount Factor (DF) for this target user ---
    print(f"\n  >>> Values for Top 20% Neighbors of Target User {target_user} (k={top_k}): <<<")
    for user_id, ds in top_20_percent_users_DS_pcc[target_user][:20]: # Show values for top 20 neighbors
        # Get the original PCC similarity for comparison
        pcc_sim_for_comparison = next((sim for uid, sim in similarity_scores_pcc[target_user] if uid == user_id), 0)
        # Recalculate the DF based on shared items and target user's threshold
        target_items_set = set(user_item_matrix[target_user].keys())
        other_items_set = set(user_item_matrix[user_id].keys())
        shared_items_count = len(target_items_set.intersection(other_items_set))
        threshold_k30 = user_counts[target_user] * 0.30
        if threshold_k30 > 0:
            DF_recalculated = min(1.0, shared_items_count / threshold_k30)
        else:
            DF_recalculated = 0.0 # Should not happen if user has items

        print(f"    Neighbor {user_id}: DS = {ds:.4f}, PCC_Sim = {pcc_sim_for_comparison:.4f}, DF = {DF_recalculated:.4f}")

    # --- EXAMPLE SECTION: Show some neighbors with DF < 1.0 from the DS calculation phase ---
    print(f"\n  >>> Example Neighbors with DF < 1.0 for Target User {target_user} (during DS calculation): <<<")
    example_printed = 0
    for other_user, raw_sim in similarity_scores_pcc[target_user]: # Iterate through users used in DS calculation
        if example_printed >= 5: # Limit examples printed
            break
        target_items_set = set(user_item_matrix[target_user].keys())
        other_items_set = set(user_item_matrix[other_user].keys())
        shared_items_count = len(target_items_set.intersection(other_items_set))
        threshold_k30 = user_counts[target_user] * 0.30
        if threshold_k30 > 0:
            DF_example = min(1.0, shared_items_count / threshold_k30)
        else:
            DF_example = 0.0 # Should not happen if user has items

        if DF_example < 1.0: # Found a user with DF < 1.0
            DS_example = raw_sim * DF_example
            # Check if this user was NOT in the final top-k DS list
            top_user_ids_set = {uid for uid, ds_val in top_20_percent_users_DS_pcc[target_user]}
            if other_user not in top_user_ids_set:
                print(f"    Neighbor {other_user}: DS = {DS_example:.4f}, PCC_Sim = {raw_sim:.4f}, DF = {DF_example:.4f} (Shared Items: {shared_items_count}, Threshold: {threshold_k30:.2f})")
                example_printed += 1
    if example_printed == 0:
        print(f"    (No examples found with DF < 1.0 for this target user during DS calculation, or all were in the top-k list.)")


# --- Steps 7 & 8: Compare lists and predictions (will be analyzed in the report) ---
print("\n--- Case Study 3 Results Stored (Refined, Min Overlap = 5) ---")
# Only print lists if they exist
pcc_top_users_dict = {}
for k, v in top_20_percent_users_pcc.items():
    if v:
        pcc_top_users_dict[k] = [u[0] for u in v[:5]] # Show first 5
    else:
        pcc_top_users_dict[k] = []

DS_pcc_top_users_dict = {}
for k, v in top_20_percent_users_DS_pcc.items():
    if v:
        DS_pcc_top_users_dict[k] = [u[0] for u in v[:5]] # Show first 5
    else:
        DS_pcc_top_users_dict[k] = []

print("PCC Similarity Top 20% Users (min overlap=5):", pcc_top_users_dict)
print("DS PCC Top 20% Users (min overlap=5):", DS_pcc_top_users_dict)

# --- Step 9: Find users whose PCC became negative even though their raw cosine was positive (Comparison with CS1) ---
print("\n--- Case Study 3 Step 9: Comparing Raw Cosine (CS1) vs PCC (CS3) ---")
# This step requires the results from Case Study 1 (Raw Cosine similarities: similarity_scores_raw)
# Check if CS1 results are available in the current environment
if 'raw_sim_dict' in globals(): # Changed from similarity_scores_raw
    print("Comparing Raw Cosine (CS1) and PCC (CS3) similarities for Step 9...")
    cs3_step9_found_flipped = False
    for target_user in target_users:
        print(f"\n  Analyzing target user {target_user}:")
        # Get raw similarities for this target user (from CS1 results stored in raw_sim_dict)
        raw_sims_dict = dict(raw_sim_dict[target_user])
        # Get PCC similarities for this target user (from CS3 results stored in similarity_scores_pcc)
        pcc_sims_dict = dict(similarity_scores_pcc[target_user])

        # Find users who are common in both similarity lists
        common_users = set(raw_sims_dict.keys()).intersection(set(pcc_sims_dict.keys()))

        # Look for pairs where Raw Cosine is positive and PCC is negative (or strongly negative)
        # Adjust thresholds as needed (e.g., raw > 0.1 and pcc < -0.1)
        pos_raw_neg_pcc = [(v, raw_sims_dict[v], pcc_sims_dict[v])
                           for v in common_users
                           if raw_sims_dict[v] > 0.1 and pcc_sims_dict[v] < -0.1]

        if pos_raw_neg_pcc:
            cs3_step9_found_flipped = True
            print(f"    Users with Raw Cosine > 0.1 and PCC < -0.1 for target {target_user}:")
            for user_id, raw_sim, pcc_sim in pos_raw_neg_pcc[:10]: # Show first 10 examples
                print(f"      User {user_id}: Raw_Cos = {raw_sim:.4f}, PCC = {pcc_sim:.4f}")
        else:
            print(f"    No users found with Raw_Sim > 0.1 and PCC_Sim < -0.1 for target {target_user}.")

    if not cs3_step9_found_flipped:
        print("\n  No users found across all targets where Raw Cosine was positive (e.g., >0.1) and PCC was negative (e.g., <-0.1).")
        print("  This suggests that the mean-centering in PCC did not result in a significant negative correlation for users who had positive raw cosine similarity in this dataset/run,")
        print("  or the thresholds need adjustment (e.g., Raw>0.5, PCC<-0.5), or the min_overlap=5 filter already removed such scenarios.")
        print("  The assignment asks for 'negative PCC even though cosine was +ve'. PCC can become negative even when Raw Cosine is positive if users rate common items in opposite patterns relative to their own mean ratings.")
        print("  For example, if User A rates items [4, 5, 5] (mean=4.67) and User B rates the same items [1, 1, 2] (mean=1.33), their raw ratings are positively correlated (both high/low),")
        print("  but their deviations from their own means are negatively correlated: A's deviations [4-4.67, 5-4.67, 5-4.67] = [-0.67, +0.33, +0.33], B's deviations [1-1.33, 1-1.33, 2-1.33] = [-0.33, -0.33, +0.67].")
        print("  The correlation of these deviation vectors can be negative, leading to a negative PCC, even though their raw rating vectors are positively correlated (Raw Cosine).")

    # --- Step 9 Analysis for Report ---
    print("\n--- Case Study 3 Step 9 Analysis (Report Content) ---")
    print("  - Raw Cosine measures the similarity in the *absolute* rating values (e.g., both give high/low scores to the same items).")
    print("  - PCC measures the similarity in the *relative* rating patterns (e.g., both rate items higher/lower than their own average).")
    print("  - A positive Raw Cosine and a negative PCC indicate that while the users might rate items with similar absolute values (e.g., both often rate highly),")
    print("    their ratings deviate from their *own* average in *opposite* directions on the common items.")
    print("  - This can happen if users have different baseline rating scales (one generous, one stingy) but happen to rate the same few items similarly in absolute terms,")
    print("    or if their rating patterns on the common items are genuinely opposite relative to their own baselines.")
    print("  - This demonstrates the advantage of PCC over Raw Cosine in accounting for user rating bias.")
else:
    print("\n  Warning: 'raw_sim_dict' (from Case Study 1) not found in current environment.")
    print("  Cannot perform the comparison requested in Step 9 (Raw Cosine vs PCC).")
    print("  Please ensure the Case Study 1 cell has been run successfully in the same session before running Case Study 3.")

# --- Steps 10-13: Analysis points (will be addressed in the report) ---
print("\n--- Case Study 3 Analysis Points (Refined, Min Overlap = 5) ---")
print("10. PCC with low overlap (e.g., < min_overlap=5): Impossible by design here. With min overlap=5, PCC is more robust than with 2 common items.")
print("11. Different rating scales (generous vs strict): PCC explicitly accounts for this by centering on the user mean, making it more reliable than Raw Cosine or MC Cosine for comparing users with different rating behaviors.")
print("12. PCC based on small # of ratings: Even with min overlap=5, predictions may be less stable if the overlap is just 5 items. DS helps filter these out if 5 is less than 30% of the target user's items.")
print("13. Report comments: Discuss the advantages of PCC over Raw Cosine and MC Cosine, the combined benefit of min overlap and DS, and the overall robustness of the method for handling user bias and co-rating significance.")
# @title Part 2: Item-Based CF - Case Study 1: Mean-Centered Cosine Similarity (Refined with Auto-Selected Suitable Target Items)
print("--- Part 2: Item-Based CF - Case Study 1: Mean-Centered Cosine Similarity (Refined, Auto-Suitable Targets, Min Overlap = 5) ---")

# --- CRITICAL FIX: Select suitable target items based on popularity (ni) to ensure min overlap ---
# The original target_items (e.g., from Task 12 Sec 1) were likely the *least* rated items.
# We need more popular items for item-based CF with min_overlap=5.
min_ratings_for_target_item_cs1 = 100 # Define a minimum number of ratings for a suitable target item
suitable_target_items_cs1 = item_counts[item_counts >= min_ratings_for_target_item_cs1].head(2).index.tolist()

if len(suitable_target_items_cs1) < 2:
    print(f"Warning: Could not find 2 items with at least {min_ratings_for_target_item_cs1} ratings for Part 2 Case Study 1.")
    print("Attempting to use the original target_items. Results may be sparse (all similarities = 0).")
    target_items_cs1 = target_items # Fallback to original, expecting potential issues
else:
    target_items_cs1 = suitable_target_items_cs1
    print(f"Re-selected suitable target items for Part 2 Case Study 1 (ni >= {min_ratings_for_target_item_cs1}): {target_items_cs1}")

def cosine_similarity_item_mc_fixed(item1_id, item2_id, item_user_matrix, ri):
    """Calculate mean-centered cosine similarity between two items, considering only co-rated users."""
    users1 = set(item_user_matrix[item1_id].keys())
    users2 = set(item_user_matrix[item2_id].keys())
    common_users = users1.intersection(users2)

    # --- IMPROVEMENT: Check minimum overlap before calculating similarity ---
    min_overlap = 5 # Define a minimum number of co-raters
    if len(common_users) < min_overlap:
        return 0.0 # Return 0 if not enough overlap

    # Calculate mean ratings for both items
    mean1 = item_avg[item1_id]
    mean2 = item_avg[item2_id]

    # Calculate centered ratings and sums
    sum1_sq = sum((item_user_matrix[item1_id][u] - mean1)**2 for u in common_users)
    sum2_sq = sum((item_user_matrix[item2_id][u] - mean2)**2 for u in common_users)
    sum_prod = sum((item_user_matrix[item1_id][u] - mean1) * (item_user_matrix[item2_id][u] - mean2) for u in common_users)

    denominator = np.sqrt(sum1_sq) * np.sqrt(sum2_sq)
    if denominator == 0:
        return 0.0

    return sum_prod / denominator

# --- Step 1: Calculate mean-centered cosine similarity for auto-selected suitable target items (with min overlap check = 5) ---
similarity_scores_item_mc_fixed = {}
for target_item in target_items_cs1:
    print(f"\nCalculating mean-centered cosine similarities for target item {target_item} (min overlap = 5, ni={item_counts[target_item]})...")
    similarities = []
    for other_item in item_user_matrix.keys():
        if other_item == target_item:
            continue # Skip self-similarity
        sim_score = cosine_similarity_item_mc_fixed(target_item, other_item, item_user_matrix, item_avg)
        # Only store similarities > 0 (i.e., those that met the min overlap)
        if sim_score > 0:
            similarities.append((other_item, sim_score))

    # Sort by similarity (descending)
    similarities.sort(key=lambda x: x[1], reverse=True)
    similarity_scores_item_mc_fixed[target_item] = similarities
    print(f"  Calculated non-zero similarities with {len(similarities)} other items (after min overlap filter).")

# --- Step 2: Identify top 20% most similar items (using MC Cosine, after filtering with min overlap = 5) ---
top_20_percent_items_mc_fixed = {}
for target_item in target_items_cs1:
    total_items = len(similarity_scores_item_mc_fixed[target_item])
    if total_items == 0:
        print(f"  Warning: No items met the minimum overlap (5) criteria for target item {target_item}. Cannot select top 20%.")
        top_20_percent_items_mc_fixed[target_item] = []
        continue

    top_k = max(1, int(0.20 * total_items)) # Calculate 20% of the *filtered* list, ensure at least 1
    top_items = similarity_scores_item_mc_fixed[target_item][:top_k]
    top_20_percent_items_mc_fixed[target_item] = top_items
    print(f"\nTop 20% (k={top_k}) similar items for {target_item} (MC Cosine, min overlap=5):")
    if top_items:
        for item_id, sim in top_items[:5]: # Print top 5 for brevity
            print(f"  Item {item_id}: Sim = {sim:.4f}")
    else:
        print("  No items found after filtering.")

# --- Step 3: Predict missing ratings using top 20% (MC Cosine, after filtering with min overlap = 5) ---
# Note: This prediction logic needs the *users* who haven't rated the *target_item*.
# It uses the *items* found in Step 2 that the *user* *HAS* rated.
predictions_item_mc_fixed = {}
for target_item in target_items_cs1:
    if not top_20_percent_items_mc_fixed[target_item]: # Skip if no valid neighbors found
        print(f"  Skipping prediction for target item {target_item} due to no valid neighbors.")
        predictions_item_mc_fixed[target_item] = {}
        continue

    # Get all users who have NOT rated the target item
    users_who_did_not_rate_target = set(user_item_matrix.keys()) - set(item_user_matrix[target_item].keys())

    # Predict for these users using similar items they HAVE rated
    predictions_for_target_item = {}
    for target_user in users_who_did_not_rate_target:
        # Find items similar to target_item (using MC) that target_user HAS rated
        similar_items_user_rated = []
        for item_id, sim_score in top_20_percent_items_mc_fixed[target_item]:
            if target_user in user_item_matrix and item_id in user_item_matrix[target_user]: # Check if user rated this similar item
                similar_items_user_rated.append((item_id, sim_score))

        # Predict rating for target_item using these similar items (MC)
        sum_sim_devs = 0
        sum_sims = 0
        mean_target_user = user_avg[target_user]
        for item_id, sim in similar_items_user_rated:
            rating = user_item_matrix[target_user][item_id]
            mean_other_item = item_avg[item_id]
            deviation = rating - mean_other_item
            sum_sim_devs += sim * deviation
            sum_sims += abs(sim) # Use absolute value of the similarity

        if sum_sims != 0:
            predicted_rating = mean_target_user + (sum_sim_devs / sum_sims)
            predictions_for_target_item[target_user] = predicted_rating
        else:
            predictions_for_target_item[target_user] = mean_target_user # Fallback to user's average

    predictions_item_mc_fixed[target_item] = predictions_for_target_item
    print(f"\nPredicted ratings for {len(predictions_for_target_item)} users on {target_item} (MC Cosine, min overlap=5). Sample: {dict(list(predictions_for_target_item.items())[:3])}")

# --- Step 4: Compute DF and DS using threshold for items (e.g., min common raters) ---
# Define a threshold for item DF calculation based on common raters
MIN_COMMON_RATERS_ITEM_CS1 = 50 # Define a threshold for item DF

DS_item_mc_fixed = {}
for target_item in target_items_cs1:
    DS_scores = []
    for other_item, raw_sim in similarity_scores_item_mc_fixed[target_item]: # Iterate only over items who had MC_sim > 0 (passed min overlap)
        # DF calculation for items: based on number of common raters
        users1 = set(item_user_matrix[target_item].keys())
        users2 = set(item_user_matrix[other_item].keys())
        shared_users_count = len(users1.intersection(users2))

        if shared_users_count >= MIN_COMMON_RATERS_ITEM_CS1:
            DF = 1.0
        else:
            DF = shared_users_count / MIN_COMMON_RATERS_ITEM_CS1 if MIN_COMMON_RATERS_ITEM_CS1 > 0 else 0.0
            DF = min(DF, 1.0) # Cap DF at 1.0

        DS = raw_sim * DF # Apply DF to the MC similarity (which already passed min overlap)
        DS_scores.append((other_item, DS))

    # Sort by DS (descending)
    DS_scores.sort(key=lambda x: x[1], reverse=True)
    DS_item_mc_fixed[target_item] = DS_scores
    print(f"  Calculated DS for {len(DS_scores)} items (after min overlap=5) for {target_item} using min_common_raters={MIN_COMMON_RATERS_ITEM_CS1}.")

# --- Step 5: Select top 20% items using DS ---
top_20_percent_items_DS_mc_fixed = {}
for target_item in target_items_cs1:
    total_items_DS = len(DS_item_mc_fixed[target_item])
    if total_items_DS == 0:
        print(f"  Warning: No items had DS calculated for target item {target_item} (min overlap=5). Cannot select top 20% DS.")
        top_20_percent_items_DS_mc_fixed[target_item] = []
        continue

    top_k_DS = max(1, int(0.20 * total_items_DS)) # Calculate 20% of the *DS list*, ensure at least 1
    top_items_DS = DS_item_mc_fixed[target_item][:top_k_DS]
    top_20_percent_items_DS_mc_fixed[target_item] = top_items_DS
    print(f"\nTop 20% (k={top_k_DS}) similar items for {target_item} (DS MC Cosine, min overlap=5):")
    if top_items_DS:
        for item_id, ds in top_items_DS[:5]: # Print top 5 for brevity
            print(f"  Item {item_id}: DS = {ds:.4f}")
    else:
        print("  No items found for DS top-k.")

# --- Step 6: Use these for updated rating predictions ---
predictions_DS_item_mc_fixed = {}
for target_item in target_items_cs1:
    if not top_20_percent_items_DS_mc_fixed[target_item]: # Skip if no valid DS neighbors found
        print(f"  Skipping DS prediction for target item {target_item} due to no valid DS neighbors.")
        predictions_DS_item_mc_fixed[target_item] = {}
        continue

    # Get all users who have NOT rated the target item
    users_who_did_not_rate_target = set(user_item_matrix.keys()) - set(item_user_matrix[target_item].keys())

    # Predict for these users using DS-weighted similar items they HAVE rated
    predictions_for_target_item = {}
    for target_user in users_who_did_not_rate_target:
        # Find items similar to target_item (using DS) that target_user HAS rated
        similar_items_user_rated_DS = []
        for item_id, ds_score in top_20_percent_items_DS_mc_fixed[target_item]:
            if target_user in user_item_matrix and item_id in user_item_matrix[target_user]: # Check if user rated this similar item
                similar_items_user_rated_DS.append((item_id, ds_score))

        # Predict rating for target_item using these similar items (with DS)
        sum_DS_devs = 0
        sum_DSs = 0
        mean_target_user = user_avg[target_user]
        for item_id, DS in similar_items_user_rated_DS:
            rating = user_item_matrix[target_user][item_id]
            mean_other_item = item_avg[item_id]
            deviation = rating - mean_other_item
            sum_DS_devs += DS * deviation
            sum_DSs += abs(DS) # Use absolute value of DS

        if sum_DSs != 0:
            predicted_rating = mean_target_user + (sum_DS_devs / sum_DSs)
            predictions_for_target_item[target_user] = predicted_rating
        else:
            predictions_for_target_item[target_user] = mean_target_user # Fallback to user's average

    predictions_DS_item_mc_fixed[target_item] = predictions_for_target_item
    print(f"\nPredicted ratings for {len(predictions_for_target_item)} users on {target_item} (DS MC Cosine, min overlap=5). Sample: {dict(list(predictions_for_target_item.items())[:3])}")

    # --- CONCISE REPORTING: Show top 20% DS values, MC Similarity, and Discount Factor (DF) for this target item ---
    print(f"\n  >>> Values for Top 20% Neighbors of Target Item {target_item} (k={top_k_DS}): <<<")
    for item_id, ds in top_20_percent_items_DS_mc_fixed[target_item][:20]: # Show values for top 20 neighbors
        # Get the original MC similarity for comparison
        mc_sim_for_comparison = next((sim for iid, sim in similarity_scores_item_mc_fixed[target_item] if iid == item_id), 0)
        # Recalculate the DF based on shared users and the item threshold
        users_target = set(item_user_matrix[target_item].keys())
        other_users_set = set(item_user_matrix[item_id].keys())
        shared_users_count = len(users_target.intersection(other_users_set))
        if MIN_COMMON_RATERS_ITEM_CS1 > 0:
            DF_recalculated = min(1.0, shared_users_count / MIN_COMMON_RATERS_ITEM_CS1)
        else:
            DF_recalculated = 0.0 # Should not happen if threshold is positive

        print(f"    Neighbor {item_id}: DS = {ds:.4f}, MC_Sim = {mc_sim_for_comparison:.4f}, DF = {DF_recalculated:.4f}")

    # --- EXAMPLE SECTION: Show some neighbors with DF < 1.0 from the DS calculation phase ---
    print(f"\n  >>> Example Neighbors with DF < 1.0 for Target Item {target_item} (during DS calculation): <<<")
    example_printed = 0
    for other_item, raw_sim in similarity_scores_item_mc_fixed[target_item]: # Iterate through items used in DS calculation
        if example_printed >= 5: # Limit examples printed
            break
        users_target = set(item_user_matrix[target_item].keys())
        other_users_set = set(item_user_matrix[other_item].keys())
        shared_users_count = len(users_target.intersection(other_users_set))
        if MIN_COMMON_RATERS_ITEM_CS1 > 0:
            DF_example = min(1.0, shared_users_count / MIN_COMMON_RATERS_ITEM_CS1)
        else:
            DF_example = 0.0 # Should not happen if threshold is positive

        if DF_example < 1.0: # Found an item with DF < 1.0
            DS_example = raw_sim * DF_example
            # Check if this item was NOT in the final top-k DS list
            top_item_ids_set = {iid for iid, ds_val in top_20_percent_items_DS_mc_fixed[target_item]}
            if other_item not in top_item_ids_set:
                print(f"    Neighbor {other_item}: DS = {DS_example:.4f}, MC_Sim = {raw_sim:.4f}, DF = {DF_example:.4f} (Shared Users: {shared_users_count}, Threshold: {MIN_COMMON_RATERS_ITEM_CS1})")
                example_printed += 1
    if example_printed == 0:
        print(f"    (No examples found with DF < 1.0 for this target item during DS calculation, or all were in the top-k list.)")


# --- Steps 7 & 8: Compare lists and predictions ---
print("\n--- Step 7: Comparing Top Item Lists (MC vs DS) ---")
for target_item in target_items_cs1:
    set_mc = {item_id for item_id, _ in top_20_percent_items_mc_fixed[target_item]}
    set_ds = {item_id for item_id, _ in top_20_percent_items_DS_mc_fixed[target_item]}

    print(f"\n--- Target item {target_item} ---")
    print(f"MC top-20% size: {len(set_mc)}")
    print(f"DS top-20% size : {len(set_ds)}")
    intersection = set_mc & set_ds
    print(f"Intersection    : {len(intersection)}")
    only_in_MC = list(set_mc - set_ds)[:10] # Show first 10 unique to MC list
    only_in_DS = list(set_ds - set_mc)[:10]  # Show first 10 unique to DS list
    print(f"Only in MC (\u226410): {only_in_MC}")
    print(f"Only in DS  (\u226410): {only_in_DS}")

# --- Step 8: Compare predicted ratings ---
print("\n--- Step 8: Comparing Rating Predictions (MC vs DS) ---")
for target_item in target_items_cs1:
    pred_mc = predictions_item_mc_fixed[target_item]
    pred_ds = predictions_DS_item_mc_fixed[target_item]

    print(f"\n--- Target item {target_item} ---")
    print(f"MC predictions : {len(pred_mc)}")
    print(f"DS predictions  : {len(pred_ds)}")

    common_users = set(pred_mc.keys()) & set(pred_ds.keys())
    print(f"Common predicted users: {len(common_users)}")

    if common_users:
        diffs = [abs(pred_mc[user] - pred_ds[user]) for user in common_users]
        avg_diff = sum(diffs) / len(diffs)
        print(f"Average |MC - DS|    : {avg_diff:.3f}")
    else:
        print("No common user predictions by both methods for this item.")

# --- Step 9: Report comments ---
print("\n--- Step 9: Report Comments (Case Study 1) ---")
print("  - MC Cosine similarity accounts for item bias (mean rating), making agreement on common users' deviations more meaningful than raw cosine.")
print("  - DS calculation using a minimum common rater threshold (e.g., 50) helps prioritize items that share significant overlap with the target item.")
print("  - Step 7 shows how DS re-ranks items compared to MC similarity alone, often excluding items with lower co-rating overlap significance.")
print("  - Step 8 shows the numerical impact of applying DS on the final predictions, potentially leading to different recommendations.")
print("  - The specific items chosen as targets (based on popularity) significantly affect the ability to find neighbors meeting the min overlap and DS threshold.")

print("\n--- Part 2: Case Study 1 Complete (with auto-selected suitable targets) ---")
# @title Part 2: Item-Based CF - Case Study 2: Pearson Correlation Coefficient (PCC) (Refined with Auto-Selected Suitable Target Items & Explicit DF Reporting with Examples)
print("--- Part 2: Item-Based CF - Case Study 2: Pearson Correlation Coefficient (PCC) (Refined, Auto-Suitable Targets, Min Overlap = 5) ---")

# --- CRITICAL FIX: Select suitable target items based on popularity (item_counts) to ensure min overlap ---
# The original target_items (e.g., from Task 12 Sec 1) were likely the *least* rated items.
# We need more popular items for item-based CF with min_overlap=5.
min_ratings_for_target_item_cs2 = 100 # Define a minimum number of ratings for a suitable target item
suitable_target_items_cs2 = item_counts[item_counts >= min_ratings_for_target_item_cs2].head(2).index.tolist()

if len(suitable_target_items_cs2) < 2:
    print(f"Warning: Could not find 2 items with at least {min_ratings_for_target_item_cs2} ratings for Part 2 Case Study 2.")
    print("Attempting to use the original target_items. Results may be sparse (all similarities = 0).")
    target_items_cs2 = target_items # Fallback to original, expecting potential issues
else:
    target_items_cs2 = suitable_target_items_cs2
    print(f"Re-selected suitable target items for Part 2 Case Study 2 (item_counts >= {min_ratings_for_target_item_cs2}): {target_items_cs2}")

def pcc_similarity_item_fixed(item1_id, item2_id, item_user_matrix, item_avg):
    """Calculate Pearson Correlation Coefficient similarity between two items, considering only co-rated users."""
    users1 = set(item_user_matrix[item1_id].keys())
    users2 = set(item_user_matrix[item2_id].keys())
    common_users = users1.intersection(users2)

    # --- IMPROVEMENT: Check minimum overlap before calculating PCC ---
    min_overlap = 5 # Define a minimum number of co-raters for PCC
    if len(common_users) < min_overlap:
        return 0.0 # Return 0 if not enough overlap

    # Calculate mean ratings for both items
    mean1 = item_avg[item1_id]
    mean2 = item_avg[item2_id]

    # Calculate sums for numerator and denominators
    numerator_sum = 0
    sum_sq_diff1 = 0
    sum_sq_diff2 = 0

    for u in common_users:
        diff1 = item_user_matrix[item1_id][u] - mean1
        diff2 = item_user_matrix[item2_id][u] - mean2
        numerator_sum += diff1 * diff2
        sum_sq_diff1 += diff1**2
        sum_sq_diff2 += diff2**2

    denominator = np.sqrt(sum_sq_diff1) * np.sqrt(sum_sq_diff2)
    if denominator == 0:
        return 0.0 # Avoid division by zero if one item has no variance

    pcc = numerator_sum / denominator
    return pcc

# --- Step 1: Calculate PCC similarity for auto-selected suitable target items (with minimum overlap check = 5) ---
similarity_scores_item_pcc_fixed = {}
for target_item in target_items_cs2:
    print(f"\nCalculating PCC similarities for target item {target_item} (min overlap = 5, ni={item_counts[target_item]})...")
    similarities = []
    for other_item in item_user_matrix.keys():
        if other_item == target_item:
            continue # Skip self-similarity
        sim_score = pcc_similarity_item_fixed(target_item, other_item, item_user_matrix, item_avg)
        # Only store similarities (can be positive or negative, but must pass min overlap)
        if sim_score != 0: # Only store non-zero similarities (implies min overlap was met)
            similarities.append((other_item, sim_score))

    # Sort by similarity (descending)
    similarities.sort(key=lambda x: x[1], reverse=True)
    similarity_scores_item_pcc_fixed[target_item] = similarities
    print(f"  Calculated non-zero similarities with {len(similarities)} other items (after min overlap filter).")

# --- Step 2: Identify top 20% most similar items (using PCC, after filtering with min overlap = 5) ---
top_20_percent_items_pcc_fixed = {}
for target_item in target_items_cs2:
    total_items = len(similarity_scores_item_pcc_fixed[target_item])
    if total_items == 0:
        print(f"  Warning: No items met the minimum overlap (5) criteria for target item {target_item}. Cannot select top 20%.")
        top_20_percent_items_pcc_fixed[target_item] = []
        continue

    top_k = max(1, int(0.20 * total_items)) # Calculate 20% of the *filtered* list, ensure at least 1
    top_items = similarity_scores_item_pcc_fixed[target_item][:top_k]
    top_20_percent_items_pcc_fixed[target_item] = top_items
    print(f"\nTop 20% (k={top_k}) similar items for {target_item} (PCC, min overlap=5):")
    if top_items:
        for item_id, sim in top_items[:5]: # Print top 5 for brevity
            print(f"  Item {item_id}: Sim = {sim:.4f}")
    else:
        print("  No items found after filtering.")

# --- Step 3: Predict missing ratings using top 20% (PCC, after filtering with min overlap = 5) ---
predictions_item_pcc_fixed = {}
for target_item in target_items_cs2:
    if not top_20_percent_items_pcc_fixed[target_item]: # Skip if no valid neighbors found
        print(f"  Skipping prediction for target item {target_item} due to no valid neighbors.")
        predictions_item_pcc_fixed[target_item] = {}
        continue

    # Get all users who have NOT rated the target item
    users_who_did_not_rate_target = set(user_item_matrix.keys()) - set(item_user_matrix[target_item].keys())

    # Predict for these users using similar items they HAVE rated
    predictions_for_target_item = {}
    for target_user in users_who_did_not_rate_target:
        # Find items similar to target_item (using PCC) that target_user HAS rated
        similar_items_user_rated = []
        for item_id, sim_score in top_20_percent_items_pcc_fixed[target_item]:
            if target_user in user_item_matrix and item_id in user_item_matrix[target_user]: # Check if user rated this similar item
                similar_items_user_rated.append((item_id, sim_score))

        # Predict rating for target_item using these similar items (PCC)
        sum_sim_devs = 0
        sum_sims = 0
        mean_target_user = user_avg[target_user]
        for item_id, sim in similar_items_user_rated:
            rating = user_item_matrix[target_user][item_id]
            mean_other_item = item_avg[item_id]
            deviation = rating - mean_other_item
            sum_sim_devs += sim * deviation
            sum_sims += abs(sim) # Use absolute value of the similarity

        if sum_sims != 0:
            predicted_rating = mean_target_user + (sum_sim_devs / sum_sims)
            predictions_for_target_item[target_user] = predicted_rating
        else:
            predictions_for_target_item[target_user] = mean_target_user # Fallback to user's average

    predictions_item_pcc_fixed[target_item] = predictions_for_target_item
    print(f"\nPredicted ratings for {len(predictions_for_target_item)} users on {target_item} (PCC, min overlap=5). Sample: {dict(list(predictions_for_target_item.items())[:3])}")

# --- Step 4: Compute DF and DS using item-specific threshold ---
# Use the same threshold as Case Study 1 for consistency
MIN_COMMON_RATERS_ITEM_CS2 = 50 # Define a threshold for item DF calculation

DS_item_pcc_fixed = {}
for target_item in target_items_cs2:
    DS_scores = []
    for other_item, raw_sim in similarity_scores_item_pcc_fixed[target_item]: # Iterate only over items who had PCC_sim != 0 (passed min overlap)
        # DF calculation for items: based on number of common raters
        users1 = set(item_user_matrix[target_item].keys())
        users2 = set(item_user_matrix[other_item].keys())
        shared_users_count = len(users1.intersection(users2))

        if shared_users_count >= MIN_COMMON_RATERS_ITEM_CS2:
            DF = 1.0
        else:
            DF = shared_users_count / MIN_COMMON_RATERS_ITEM_CS2 if MIN_COMMON_RATERS_ITEM_CS2 > 0 else 0.0
            DF = min(DF, 1.0) # Cap DF at 1.0

        DS = raw_sim * DF # Apply DF to the PCC similarity (which already passed min overlap)
        DS_scores.append((other_item, DS))

    # Sort by DS (descending)
    DS_scores.sort(key=lambda x: x[1], reverse=True)
    DS_item_pcc_fixed[target_item] = DS_scores
    print(f"  Calculated DS for {len(DS_scores)} items (after min overlap=5) for {target_item} using min_common_raters={MIN_COMMON_RATERS_ITEM_CS2}.")

# --- Step 5: Select top 20% items using DS (PCC) ---
top_20_percent_items_DS_pcc_fixed = {}
for target_item in target_items_cs2:
    total_items_DS = len(DS_item_pcc_fixed[target_item])
    if total_items_DS == 0:
        print(f"  Warning: No items had DS calculated for target item {target_item} (min overlap=5). Cannot select top 20% DS.")
        top_20_percent_items_DS_pcc_fixed[target_item] = []
        continue

    top_k_DS = max(1, int(0.20 * total_items_DS)) # Calculate 20% of the *DS list*, ensure at least 1
    top_items_DS = DS_item_pcc_fixed[target_item][:top_k_DS]
    top_20_percent_items_DS_pcc_fixed[target_item] = top_items_DS
    print(f"\nTop 20% (k={top_k_DS}) similar items for {target_item} (DS PCC, min overlap=5):")
    if top_items_DS:
        for item_id, ds in top_items_DS[:5]: # Print top 5 for brevity
            print(f"  Item {item_id}: DS = {ds:.4f}")
    else:
        print("  No items found for DS top-k.")

# --- Step 6: Use these for updated rating predictions (PCC with DS) ---
predictions_DS_item_pcc_fixed = {}
for target_item in target_items_cs2:
    if not top_20_percent_items_DS_pcc_fixed[target_item]: # Skip if no valid DS neighbors found
        print(f"  Skipping DS prediction for target item {target_item} due to no valid DS neighbors.")
        predictions_DS_item_pcc_fixed[target_item] = {}
        continue

    # Get all users who have NOT rated the target item
    users_who_did_not_rate_target = set(user_item_matrix.keys()) - set(item_user_matrix[target_item].keys())

    # Predict for these users using DS-weighted similar items they HAVE rated
    predictions_for_target_item = {}
    for target_user in users_who_did_not_rate_target:
        # Find items similar to target_item (using DS PCC) that target_user HAS rated
        similar_items_user_rated_DS = []
        for item_id, ds_score in top_20_percent_items_DS_pcc_fixed[target_item]:
            if target_user in user_item_matrix and item_id in user_item_matrix[target_user]: # Check if user rated this similar item
                similar_items_user_rated_DS.append((item_id, ds_score))

        # Predict rating for target_item using these similar items (with DS PCC)
        sum_DS_devs = 0
        sum_DSs = 0
        mean_target_user = user_avg[target_user]
        for item_id, DS in similar_items_user_rated_DS:
            rating = user_item_matrix[target_user][item_id]
            mean_other_item = item_avg[item_id]
            deviation = rating - mean_other_item
            sum_DS_devs += DS * deviation
            sum_DSs += abs(DS) # Use absolute value of DS

        if sum_DSs != 0:
            predicted_rating = mean_target_user + (sum_DS_devs / sum_DSs)
            predictions_for_target_item[target_user] = predicted_rating
        else:
            predictions_for_target_item[target_user] = mean_target_user # Fallback to user's average

    predictions_DS_item_pcc_fixed[target_item] = predictions_for_target_item
    print(f"\nPredicted ratings for {len(predictions_for_target_item)} users on {target_item} (DS PCC, min overlap=5). Sample: {dict(list(predictions_for_target_item.items())[:3])}")

    # --- CONCISE REPORTING: Show top 20% DS values, PCC Similarity, and Discount Factor (DF) for this target item ---
    print(f"\n  >>> Values for Top 20% Neighbors of Target Item {target_item} (k={top_k_DS}): <<<")
    for item_id, ds in top_20_percent_items_DS_pcc_fixed[target_item][:20]: # Show values for top 20 neighbors
        # Get the original PCC similarity for comparison
        pcc_sim_for_comparison = next((sim for iid, sim in similarity_scores_item_pcc_fixed[target_item] if iid == item_id), 0)
        # Recalculate the DF based on shared users and the item threshold
        users_target = set(item_user_matrix[target_item].keys())
        other_users_set = set(item_user_matrix[item_id].keys())
        shared_users_count = len(users_target.intersection(other_users_set))
        if MIN_COMMON_RATERS_ITEM_CS2 > 0:
            DF_recalculated = min(1.0, shared_users_count / MIN_COMMON_RATERS_ITEM_CS2)
        else:
            DF_recalculated = 0.0 # Should not happen if threshold is positive

        print(f"    Neighbor {item_id}: DS = {ds:.4f}, PCC_Sim = {pcc_sim_for_comparison:.4f}, DF = {DF_recalculated:.4f}")

    # --- EXAMPLE SECTION: Show some neighbors with DF < 1.0 from the DS calculation phase ---
    print(f"\n  >>> Example Neighbors with DF < 1.0 for Target Item {target_item} (during DS calculation): <<<")
    example_printed = 0
    for other_item, raw_sim in similarity_scores_item_pcc_fixed[target_item]: # Iterate through items used in DS calculation
        if example_printed >= 5: # Limit examples printed
            break
        users_target = set(item_user_matrix[target_item].keys())
        other_users_set = set(item_user_matrix[other_item].keys())
        shared_users_count = len(users_target.intersection(other_users_set))
        if MIN_COMMON_RATERS_ITEM_CS2 > 0:
            DF_example = min(1.0, shared_users_count / MIN_COMMON_RATERS_ITEM_CS2)
        else:
            DF_example = 0.0 # Should not happen if threshold is positive

        if DF_example < 1.0: # Found an item with DF < 1.0
            DS_example = raw_sim * DF_example
            # Check if this item was NOT in the final top-k DS list
            top_item_ids_set = {iid for iid, ds_val in top_20_percent_items_DS_pcc_fixed[target_item]}
            if other_item not in top_item_ids_set:
                print(f"    Neighbor {other_item}: DS = {DS_example:.4f}, PCC_Sim = {raw_sim:.4f}, DF = {DF_example:.4f} (Shared Users: {shared_users_count}, Threshold: {MIN_COMMON_RATERS_ITEM_CS2})")
                example_printed += 1
    if example_printed == 0:
        print(f"    (No examples found with DF < 1.0 for this target item during DS calculation, or all were in the top-k list.)")


# --- Steps 7 & 8: Compare lists and predictions ---
print("\n--- Step 7: Comparing Top Item Lists (PCC vs DS) ---")
for target_item in target_items_cs2:
    set_pcc = {item_id for item_id, _ in top_20_percent_items_pcc_fixed[target_item]}
    set_ds = {item_id for item_id, _ in top_20_percent_items_DS_pcc_fixed[target_item]}

    print(f"\n--- Target item {target_item} ---")
    print(f"PCC top-20% size: {len(set_pcc)}")
    print(f"DS top-20% size : {len(set_ds)}")
    intersection = set_pcc & set_ds
    print(f"Intersection    : {len(intersection)}")
    only_in_PCC = list(set_pcc - set_ds)[:10] # Show first 10 unique to PCC list
    only_in_DS = list(set_ds - set_pcc)[:10]  # Show first 10 unique to DS list
    print(f"Only in PCC (\u226410): {only_in_PCC}")
    print(f"Only in DS  (\u226410): {only_in_DS}")

# --- Step 8: Compare predicted ratings ---
print("\n--- Step 8: Comparing Rating Predictions (PCC vs DS) ---")
for target_item in target_items_cs2:
    pred_pcc = predictions_item_pcc_fixed[target_item]
    pred_ds = predictions_DS_item_pcc_fixed[target_item]

    print(f"\n--- Target item {target_item} ---")
    print(f"PCC predictions : {len(pred_pcc)}")
    print(f"DS predictions  : {len(pred_ds)}")

    common_users = set(pred_pcc.keys()) & set(pred_ds.keys())
    print(f"Common predicted users: {len(common_users)}")

    if common_users:
        diffs = [abs(pred_pcc[user] - pred_ds[user]) for user in common_users]
        avg_diff = sum(diffs) / len(diffs)
        print(f"Average |PCC - DS|    : {avg_diff:.3f}")
    else:
        print("No common user predictions by both methods for this item.")

# --- Step 9: Report comments ---
print("\n--- Step 9: Report Comments (Case Study 2) ---")
print("  - PCC similarity accounts for user rating bias (deviations from mean) and can capture positive/negative correlations.")
print("  - DS calculation using a minimum common rater threshold (e.g., 50) helps prioritize items that share significant overlap with the target item.")
print("  - Step 7 shows how DS re-ranks items compared to PCC alone, often excluding items with lower co-rating overlap significance.")
print("  - Step 8 shows the numerical impact of applying DS on the final predictions, potentially leading to different recommendations.")
print("  - PCC can yield negative similarities, indicating opposing rating patterns, which Raw Cosine or MC Cosine might miss or interpret differently.")
print("  - The specific items chosen as targets (based on popularity) significantly affect the ability to find neighbors meeting the min overlap and DS threshold.")

print("\n--- Part 2: Case Study 2 Complete (with auto-selected suitable targets) ---")
